Evaluation Approach / Metric,Appropriate Data Types,Mathematic Definition (if applicable),ArcPy function (if applicable),How to do in python,What metrics is this approach similar / different to?,Sources
Confusion Matrix,Discrete (Binary or Multi-field/Categorical),"No specific equation, but can be performed through Python functions",arcpy.gp.ComputeConfusionMatrix(),sklearn.metrics.confusion_matrix(),"Similar: Sensitivity Analysis, F1-Score (Related to accuracy, precision, and recall) | Different: Any continuous evaluation",ArcPy
Accuracy,Discrete (Binary or Multi-field/Categorical),(TP + TN)/(TP + TN + FP + FN),N/A,sklearn.metrics.accuracy_score(),Similar: Percent Error (Related to confusion matrix) | Different: Any continuous evaluation,sklearn
Precision,Discrete (Binary or Multi-field/Categorical),TP/(TP + FP),N/A,sklearn.metrics.precision_score(),"Similar: F1 Score, Recall (Related to confusion matrix) | Different: Any continuous evaluation",sklearn
Recall,Discrete (Binary or Multi-field/Categorical),TP/(TP + FN),N/A,sklearn.metrics.recall_score(),"Similar: F1 Score, Precision (Related to confusion matrix) | Different: Any continuous evaluation",sklearn
True Positives,Discrete (Binary or Multi-field/Categorical),"No equation, as true positives are determined by the study",N/A,np.diag(confusion_matrix),"Similar: False Positives, True Negatives, False Negatives (Created from confusion matrix) | Different: Any continuous evaluation",sklearn
False Position,Discrete (Binary or Multi-field/Categorical),"No equation, as false positives are determined by the study",N/A,confusion_matrix.sum(axis=0) - np.diag(confusion_matrix) ,"Similar: True Positives, True Negatives, False Negatives (Created from confusion matrix) | Different: Any continuous evaluation",sklearn
Receiver Operator Characteristic (ROC) Curve and Area Under the Curve,Discrete (Binary or Multi-field/Categorical),"No equation, qualitative analysis determined by the study",N/A,sklearn.metrics.roc_auc_score(),Similar: Precision-Recall Curve | Different: Any continuous evaluation,sklearn
R-squared,Continuous,1 - (?(yactual - ypredicted))/(?(yactual - yavg)),N/A,sklearn.metrics.r2_score(),Similar: Adjusted R-squared | Different: Any discrete evaluation,sklearn
Adjusted R-Squared,Continuous,1 - ((1 - r2)(n - 1))/(n - p - 1),N/A,1 - ((1 - sklearn.metrics.r2_score())(n - 1))/(n - p - 1) (add r-squared value to equation),Similar: R-squared | Different: Any discrete evaluation,sklearn
Root Mean Square Error,Continuous,sqrt[(?(Pi - Oi)2)/n],N/A,sklearn.metrics.mean_squared_error(),Similar: Mean Absolute Error | Different: Any discrete evaluation,sklearn
Mean Absolute Error,Continuous,(?|yi - xi|)/n,N/A,sklearn.metrics.mean_absolute_error(),Similar: Root Mean Square Error | Different: Any discrete evaluation,sklearn
Residual Standard Error,Continuous,sqrt[(?(yobserved - ypredicted)2)/(Nobservations - Nparameters)],N/A,numpy.sqrt(sklearn.metrics.mean_absolute_error()),"Similar: Mean Absolute Error, Root Mean Square Error | Different: Any discrete evaluation",sklearn
Akaike’s Information Criterion (AIC),Continuous,2k - 2ln(Lmax of likelihood fn),N/A,"statsmodels.OLS(y,x).fit().aic",Similar: BIC | Different: Any discrete evaluation,statsmodels
Bayesian Information Criterion (BIC),Continuous,kln(n) - 2ln(Lmax of likelihood fn),N/A,"statsmodels.OLS(y,x).fit().bic",Similar: AIC | Different: Any discrete evaluation,statsmodels
